{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damianodea/hpc_2025/blob/main/%5BPUBLIC%5D_HPQC_HandsOn_DT_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfi_boTqVWl8"
      },
      "source": [
        "# **Decision Trees** (DT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrfEJ6VwWuDw"
      },
      "source": [
        "Import common modules. Make sure matplotlib plots figures inline. Check Python 3 or later is installed (Python 2.x may work, but it is deprecated in colab, so better to move to v3). Check sklearn ≥0.20 is installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZuQjwLKXBUz"
      },
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make the notebook's output stable across subsequent runs\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaLYz7WjYDzE"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # petal length and width\n",
        "y = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)  #We instantiate a DT classifier\n",
        "tree_clf.fit(X, y) # Training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjWqertcxuzZ"
      },
      "source": [
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file=os.path.join(\"./iris_tree.dot\"),\n",
        "        feature_names=iris.feature_names[2:],\n",
        "        class_names=iris.target_names,\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "print(iris.target_names)\n",
        "\n",
        "Source.from_file(os.path.join(\"./iris_tree.dot\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXTqgXJxxuww"
      },
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb_5Vmqaxut0"
      },
      "source": [
        "tree_clf.predict([[5, 1.5]]) # Versicolor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfQcsE_5fv28"
      },
      "source": [
        "## <font color=red>Exercise</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AnVGqbjfvo0"
      },
      "source": [
        "Train and fine-tune a Decision Tree for the moons dataset by following these steps:\n",
        "\n",
        "\n",
        "1.   Use [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) (from `sklearn.model_selection`) to split the dataset into a training set and a test set (20\\% test)\n",
        "2.   Use grid search with cross-validation (with the help of the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class) to find good hyperparameter values for a DecisionTreeClassifier (hint: try various values for max_leaf_nodes\n",
        "3.   Train it on the full training set using these hyperparameters, and measure your model’s performance on the test set.\n",
        "\n",
        "You should get roughly 97\\% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# type your code below"
      ],
      "metadata": {
        "id": "HDAWqMfhm9Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCVhePEbfvlj"
      },
      "source": [
        "### <font color='green'>Solution</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBwz7qPVg-de"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_leaf_nodes': list(range(2, 50)),\n",
        "    'max_depth': list(range(1, 7)),\n",
        "    'min_samples_split': [2, 3, 4]\n",
        "}\n",
        "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
        "                              params,\n",
        "                              cv=3)\n",
        "\n",
        "grid_search_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best estimator is:\")\n",
        "grid_search_cv.best_estimator_"
      ],
      "metadata": {
        "id": "ccjoYnnXnxPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = grid_search_cv.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "_uI_mBydpCF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble models"
      ],
      "metadata": {
        "id": "QjRfOl4T_ZcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging algorithms"
      ],
      "metadata": {
        "id": "awqlAt7iBBw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagged Decision Trees"
      ],
      "metadata": {
        "id": "5HEbdE0NBIa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example below is an example of using the [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) with the Classification and Regression Trees algorithm. A total of 100 trees are created.\n"
      ],
      "metadata": {
        "id": "Z0jLKFCpBP7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#\n",
        "from sklearn.ensemble import BaggingClassifier                     # <---"
      ],
      "metadata": {
        "id": "jD-eRcmYBKhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try a simple decision tree classifier."
      ],
      "metadata": {
        "id": "yCnCg59nEA5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "model = DecisionTreeClassifier(random_state=seed)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "UtfnavfIEB48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then try to do better with Bagging."
      ],
      "metadata": {
        "id": "ZEpH8iG4EMOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagged Decision Trees for Classification\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "cart = DecisionTreeClassifier(random_state=seed)\n",
        "num_trees = 100\n",
        "model = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=seed, bootstrap = False)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "AnXsH2JbCXVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(NOTE: running the cell above should take some more time than usual..)*"
      ],
      "metadata": {
        "id": "gyPi4u1WEdom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, try to change one parameter above, `bootstrap = True` and rerun and see what happens..."
      ],
      "metadata": {
        "id": "cPklqBLSEelT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example in the latter way, we get a more robust estimate of model accuracy."
      ],
      "metadata": {
        "id": "QpF5hBsVEpS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "cOp8LhhYE1AL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forests is **an extension of bagged decision trees**.\n",
        "\n",
        "You can construct a Random Forest model for classification using the RandomForestClassifier class, documented here. The example below demonstrates using Random Forest for classification with 100 trees and split points chosen from a random selection of 3 features."
      ],
      "metadata": {
        "id": "Yo48BoqiFNo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier                    # <---\n",
        "\n",
        "# Random Forest Classification\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "rrVoCIIJFMr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(NOTE: running the cell above should take some more time than usual..)\n",
        "\n",
        "Running the example provides a mean estimate of classification accuracy."
      ],
      "metadata": {
        "id": "f-fWB4mUFctm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosting Algorithms"
      ],
      "metadata": {
        "id": "YD67lJydFjPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost"
      ],
      "metadata": {
        "id": "P_y8JvQHF48t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier                    # <---\n",
        "\n",
        "# AdaBoost Classification\n",
        "num_trees = 30\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "zq92cxDoFney"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example provides a mean estimate of classification accuracy."
      ],
      "metadata": {
        "id": "q2jkjgHrFtgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "vTrHwDodF8L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier                    # <---\n",
        "\n",
        "# Stochastic Gradient Boosting Classification\n",
        "num_trees = 100\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "13FBTRn8F-kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extreme gradient boosting (XGBoost)"
      ],
      "metadata": {
        "id": "86Ya5aexGaaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb     # <--- Notice the different library\n",
        "\n",
        "num_trees = 100\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "model = xgb.XGBClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "cQf7y8yBGeXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnPfTnRBmn-9"
      },
      "source": [
        "## Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyXnXpclezsG"
      },
      "source": [
        "_Credits: Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd Edition) by Aurélien Géron, O'Reilly Media Inc., 2019_"
      ]
    }
  ]
}